{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a VAE for shits n Giggles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  setting constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - building Sampling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Becuase VAE need to sample from a distribution, we need to build a function that will sample from that distribution at the same dim as the input  \n",
    "https://keras.io/examples/generative/vae/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "    \n",
    "def sampling(mu, sigma):\n",
    "    \"\"\"Direct call to the sampling function instead of a class layers.Layer (like above)\"\"\"\n",
    "    batch = tf.shape(mu)[0]\n",
    "    dim = tf.shape(mu)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return mu + tf.exp(0.5 * sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - building a model\n",
    "#### Encoder\n",
    "We're going to use  a sequentail model to get this done, but we are going to split it into the Encoder/Decoder aspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want you to notice the `layers.Dense(latent_dim + latent_dim)` part. Remeber, we are building a guassian distribution distribution to pull one, so we have two variables **per gaussian distribution** to optimize for - mean and std. So latent_dim x (mean, std) = latent_dim * mean + latent_dim * std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder = tf.keras.Sequential([\n",
    "    layers.InputLayer(input_shape=(28, 28, 1)),\n",
    "    layers.Conv2D(filters=8, \n",
    "                  kernel_size=(3,3),\n",
    "                  #strides=(2, 2), \n",
    "                  activation='relu'),\n",
    "    layers.Conv2D(filters=32, \n",
    "                  kernel_size=(3,3),\n",
    "                  #strides=(2, 2), \n",
    "                  activation='relu'),\n",
    "     layers.Conv2D(filters=64,\n",
    "                   kernel_size=(3,3), \n",
    "                   #strides=(2, 2), \n",
    "                   activation='relu'),\n",
    "     tf.keras.layers.Flatten(),\n",
    "     layers.Dense(16, activation = 'tanh'),\n",
    "     layers.Dense(latent_dim + latent_dim) #first latent_dim is for mu, second is for std\n",
    "     \n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "2D convolution layer (e.g. spatial convolution over images).\n",
       "\n",
       "This layer creates a convolution kernel that is convolved\n",
       "with the layer input to produce a tensor of\n",
       "outputs. If `use_bias` is True,\n",
       "a bias vector is created and added to the outputs. Finally, if\n",
       "`activation` is not `None`, it is applied to the outputs as well.\n",
       "\n",
       "When using this layer as the first layer in a model,\n",
       "provide the keyword argument `input_shape`\n",
       "(tuple of integers, does not include the sample axis),\n",
       "e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
       "in `data_format=\"channels_last\"`.\n",
       "\n",
       "Arguments:\n",
       "  filters: Integer, the dimensionality of the output space\n",
       "    (i.e. the number of output filters in the convolution).\n",
       "  kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
       "    height and width of the 2D convolution window.\n",
       "    Can be a single integer to specify the same value for\n",
       "    all spatial dimensions.\n",
       "  strides: An integer or tuple/list of 2 integers,\n",
       "    specifying the strides of the convolution along the height and width.\n",
       "    Can be a single integer to specify the same value for\n",
       "    all spatial dimensions.\n",
       "    Specifying any stride value != 1 is incompatible with specifying\n",
       "    any `dilation_rate` value != 1.\n",
       "  padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
       "  data_format: A string,\n",
       "    one of `channels_last` (default) or `channels_first`.\n",
       "    The ordering of the dimensions in the inputs.\n",
       "    `channels_last` corresponds to inputs with shape\n",
       "    `(batch, height, width, channels)` while `channels_first`\n",
       "    corresponds to inputs with shape\n",
       "    `(batch, channels, height, width)`.\n",
       "    It defaults to the `image_data_format` value found in your\n",
       "    Keras config file at `~/.keras/keras.json`.\n",
       "    If you never set it, then it will be \"channels_last\".\n",
       "  dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
       "    the dilation rate to use for dilated convolution.\n",
       "    Can be a single integer to specify the same value for\n",
       "    all spatial dimensions.\n",
       "    Currently, specifying any `dilation_rate` value != 1 is\n",
       "    incompatible with specifying any stride value != 1.\n",
       "  activation: Activation function to use.\n",
       "    If you don't specify anything, no activation is applied\n",
       "    (ie. \"linear\" activation: `a(x) = x`).\n",
       "  use_bias: Boolean, whether the layer uses a bias vector.\n",
       "  kernel_initializer: Initializer for the `kernel` weights matrix.\n",
       "  bias_initializer: Initializer for the bias vector.\n",
       "  kernel_regularizer: Regularizer function applied to\n",
       "    the `kernel` weights matrix.\n",
       "  bias_regularizer: Regularizer function applied to the bias vector.\n",
       "  activity_regularizer: Regularizer function applied to\n",
       "    the output of the layer (its \"activation\")..\n",
       "  kernel_constraint: Constraint function applied to the kernel matrix.\n",
       "  bias_constraint: Constraint function applied to the bias vector.\n",
       "\n",
       "Input shape:\n",
       "  4D tensor with shape:\n",
       "  `(samples, channels, rows, cols)` if data_format='channels_first'\n",
       "  or 4D tensor with shape:\n",
       "  `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
       "\n",
       "Output shape:\n",
       "  4D tensor with shape:\n",
       "  `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
       "  or 4D tensor with shape:\n",
       "  `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
       "  `rows` and `cols` values might have changed due to padding.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Conv2DTranspose, DepthwiseConv2D, Conv2D\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?layers.Conv2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
